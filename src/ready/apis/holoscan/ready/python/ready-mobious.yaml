%YAML 1.2
---
replayer:
  #
  #
  # VideoStreamReplayer
  #
  #
  # https://github.com/nvidia-holoscan/holoscan-sdk/blob/main/include/holoscan/operators/video_stream_replayer/video_stream_replayer.hpp
  #
  #
  basename: "video_30_duplicated_frames_of_1_1i_Ll_1_channels3" #mobious
  #
  frame_rate: 0 # as specified in timestamps
  repeat: true # default: false
  realtime: true # default: true
  count: 0 # default: 0 (no frame count restriction)

source:
  #
  #
  # V4L2VideoCaptureOp
  # https://github.com/nvidia-holoscan/holoscan-sdk/blob/main/python/holoscan/operators/v4l2_video_capture/pydoc.hpp
  #
  #
  # TODO: add device arg to python script
  #         source_device = source_args["device"]
  #
  #
  # | Input device. /dev/video0 is generally the defautl input
  device: "/dev/video0"
  #device: "/dev/video4"

  # | App will auto-select default width and height if not provided
  # | For performance, you may want to specify these parameters yourself.
  # | See this app's readme file for details.
  width: 640
  height: 480
  # width: 640
  # height: 360

  # | App will auto-select the default "pixel_format" for your device if not provided.
  # | See this app's readme file for details.
  pixel_format: "YUYV"

  # | These properties might not be supported for all v4l2 nodes.
  # | The app will attempt to do auto exposure and gain if not provided. If auto is not supported,
  # | it will use the defaults defined by your device.
  # | See this app's readme file for details.
  # exposure_time: 500
  # gain: 100


model:
  #
  #
  #TODO add args to __init__ in READYapp class
  #
  #
  path: "/workspace/volumes/ready/data/mobious"
  name: "_weights_10-09-24_06-35-14-sim-BHWC.onnx"


inference:
  #
  #
  # InferenceOp
  #
  # https://github.com/nvidia-holoscan/holoscan-sdk/blob/main/include/holoscan/operators/inference/inference.hpp
  #
  #
  backend: "trt"
  pre_processor_map:
    "ready_model": ["out_preprocessor"]
  inference_map:
    "ready_model": ["unet_out"]
  enable_fp16: False #Use 16-bit floating point computations. Optional (default: `false`).
  parallel_inference: true # optional param, default to true
  infer_on_cpu: false # optional param, default to false
  input_on_cuda: true # optional param, default to true
  output_on_cuda: true # optional param, default to true
  transmit_on_cuda: true # optional param, default to true
  is_engine_path: false # optional param, default to false


preprocessor_replayer:
  #
  #
  # FormatConverter
  #
  #https://github.com/nvidia-holoscan/holoscan-sdk/blob/main/include/holoscan/operators/format_converter/format_converter.hpp
  #
  #
  #in_tensor_name: #- **in_tensor_name**: The name of the input tensor. Optional (default: `""`).
  out_tensor_name: "out_preprocessor"
  scale_min: 1.0
  scale_max: 252.0
  #alpha_value: #Unsigned integer in range [0, 255], indicating the alpha channel value to use
                #when converting from RGB to RGBA. Optional (default: `255`).
  #in_dtype: "rgba8888" #for four channles
  #in_dtype: "float32" ?
  resize_width: 640 #320
  resize_height: 400 #200
  out_dtype: "float32"
  #out_channel_order: [0, 1, 2, 3]
  #out_channel_order: [0, 1, 2]
  #out_channel_order: [0, 2, 1]
  #out_channel_order: [2, 1, 0]
  #out_channel_order: [2, 0, 1]
  #out_channel_order: [1, 0, 2]
  #out_channel_order: [1, 2, 0]

preprocessor_v4l2:
  #
  #
  # Preprocessor FormatConverterOp() for v4l2
  # DROP ALPHA CHANNEL
  #
  #
  out_tensor_name: out_preprocessor
  in_dtype: "rgba8888" #for four channles
  out_dtype: "float32"
  resize_width: 640
  resize_height: 400
  scale_min: 1.0
  scale_max: 252.0

pre_info_op_replayer:  #Pre Info Operator
format_input:  #FormatInferenceInputOp
post_inference_op:  #Info Operator
info_op:  #Info Operator

segpostprocessor:
  #
  #
  # SegmentationPostprocessor
  # This tensor will have unsigned 8-bit integer data type and shape (H, W, 1).
  # https://github.com/nvidia-holoscan/holoscan-sdk/blob/main/include/holoscan/operators/segmentation_postprocessor/segmentation_postprocessor.hpp
  #
  in_tensor_name: unet_out
  network_output_type: softmax #softmax layer for multiclass segmentation
  #network_output_type: sigmoid #sigmoid layer for binary segmentation
  #network_output_type: None
  data_format: nchw
  #data_format: nhwc


viz:
  #
  #
  # Holoviz
  # https://github.com/nvidia-holoscan/holoscan-sdk/blob/main/include/holoscan/operators/holoviz/holoviz.hpp
  #
  #
  window_title: "READY demo"
  width: 640
  height: 400
  tensors:
    - name: ""
      type: color
      opacity: 1.0
      priority: 0
    - name: "pupil_cXcY"
      type: crosses
      opacity: 0.85
      color: [0.6, 0.1, 0.6, 0.8] #RGB for purple with alpha 0.8
      line_width: 5.0 #for crosses only
      point_size: 10.0 #for points only
      priority: 2
    - name: "point_coords"
      type: points
      opacity: 0.85
      color: [0.9, 0.9, 0.9, 0.8] #RGB for purple with alpha 0.8
      point_size: 3.0 #for points only
      priority: 2
    - name: "out_tensor"
      type: color_lut
      opacity: 1.0
      priority: 0
  color_lut: [
    [0.65, 0.81, 0.89, 0.01], #background #RGB for light blue & alpha=0.1
    [0.3, 0.3, 0.9, 0.5], #sclera  #RGB for blue & alpha=0.5
    [0.1, 0.8, 0.2, 0.5], #Iris    #RGB for green & alpha=0.5
    [0.9, 0.9, 0.3, 0.8], #Pupil   #RGB for yellow & alpha=0.8 
    #https://rgbcolorpicker.com/0-1
    ]
